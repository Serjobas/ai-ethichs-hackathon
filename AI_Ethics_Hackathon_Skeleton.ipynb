{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score,  precision_score, recall_score, balanced_accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "qBSb-lG8vybA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset Exploration\n",
        "## a) Load the df_hackathon.csv dataset - (hint: use pandas)\n",
        "Assign it to a variable called df."
      ],
      "metadata": {
        "id": "yfp0QDU_wZOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Using pandas examine the numerical features of the dataset\n",
        "\n",
        "Examine the 7+1 figure summary (count, mean, std, min, 1Q, median, 3Q, max)\n",
        "\n",
        "- Î‘re there any missing feature values?\n",
        "- Are there any unexpected (or extreme) feature values?"
      ],
      "metadata": {
        "id": "9FiJPCE60WNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise in histograms the numerical features.\n",
        "\n",
        "- Is there significant data skewness in any of the variables?"
      ],
      "metadata": {
        "id": "qXCED4as2LYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Using pandas examine the categorical features of the dataset\n",
        "\n",
        "- Are there any significant inequalities in the dataset?\n",
        "- Are there any features with missing values?"
      ],
      "metadata": {
        "id": "je2ip0T82pjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) further dataset exploration\n",
        "Using the facets library visualise the dataset (use code below). Try different combinations. Do you notice any patterns in the dataset that might influence the model's predictions?"
      ],
      "metadata": {
        "id": "7cPhdFUmOq1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "\n",
        "vis_df = df.to_json(orient='records')\n",
        "\n",
        "HTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n",
        "        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n",
        "        <facets-dive id=\"elem\" height=\"600\"></facets-dive>\n",
        "        <script>\n",
        "          var data = {jsonstr};\n",
        "          document.querySelector(\"#elem\").data = data;\n",
        "        </script>\"\"\"\n",
        "html = HTML_TEMPLATE.format(jsonstr=vis_df)\n",
        "display(HTML(html))"
      ],
      "metadata": {
        "id": "dJFJ8oxyyHUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Feature Engineering"
      ],
      "metadata": {
        "id": "yX87Ua4MPJ8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Create a correlogram (hint: use pandas corr() function) and visualise it\n",
        "\n",
        "- Are there any very strong correlations (numerical features)? if yes, remove one of the features.\n",
        "- Explain how strong correlations can have an impact on some ML models."
      ],
      "metadata": {
        "id": "3DNEbH0-PVBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Deal with extreme outliers\n",
        "\n",
        "Reflect your answer on 1b). Did you identify any features with extreme outliers?\n",
        "\n",
        "If yes, explain the nature of these outliers and deal with them appropriately.\n",
        "- How many are there (in proportion to the whole dataset)?\n",
        "- would dropping these rows lead to considerable data loss?\n",
        "\n",
        "Try to also think what could result in the data collection process that resulted in them."
      ],
      "metadata": {
        "id": "LyPXup3pRAcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Deal with features with missing values"
      ],
      "metadata": {
        "id": "QVC8Q0VrT36l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by splitting your into training (X_train, y_train) and testing sets (X_test, y_test) in an 80-20 split (hint: use train_test_split from sklearn). Use random_state = 42.\n",
        "\n",
        "Reflect again on exercise 2c. Did you identify any numerical features with missing values?\n",
        "\n",
        "- Impute the values in the feature with the missing values using the numerical features.\n",
        "- Check (e.g. by plotting) the distribution of the feature with the missing values before and after imputation. Ensure that the imputation did not bias/skew the feature's distribution.\n",
        "\n",
        "Just as a reminder, the dependent variable (y) is gringotts_approved_loan.\n",
        "\n",
        "`Tip:` It is essential to train the imputation model only on the training data to avoid [data leakage](https://machinelearningmastery.com/data-preparation-without-data-leakage/). Then use the trained imputation model to also predict the most appropriate value for the testing data. Please feel free to use the impute_missing_values function.\n"
      ],
      "metadata": {
        "id": "JR577pWZXYP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Save the imputed dfs as `X_train_imputed` and `X_test_imputed`.\n",
        "\n"
      ],
      "metadata": {
        "id": "taM4mZJoXVg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impute_missing_values(feature_with_missing, X_train, X_test):\n",
        "    # One-hot encode categorical features.\n",
        "    X_train_encoded = pd.get_dummies(X_train)\n",
        "    X_test_encoded = pd.get_dummies(X_test)\n",
        "\n",
        "    X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='inner', axis=1)\n",
        "\n",
        "    # Impute using KNN imputer (model-based approach). Importantly, we are only fitting\n",
        "    # the imputer on the training data.\n",
        "    knn_imputer_full = KNNImputer(n_neighbors=5)\n",
        "    X_train_imputed = knn_imputer_full.fit_transform(X_train_encoded)\n",
        "    X_test_imputed = knn_imputer_full.transform(X_test_encoded)\n",
        "\n",
        "    # Convert back to pandas DataFrame, ensuring column names are retained.\n",
        "    X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train_encoded.columns, index=X_train_encoded.index)\n",
        "    X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test_encoded.columns, index=X_test_encoded.index)\n",
        "\n",
        "    # Replace the imputed column to the original X_train and X_test passed in.\n",
        "    X_train[feature_with_missing] = X_train_imputed[feature_with_missing]\n",
        "    X_test[feature_with_missing] = X_test_imputed[feature_with_missing]\n",
        "\n",
        "    return X_train, X_test"
      ],
      "metadata": {
        "id": "etQdQ3w7Q8Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train RF model"
      ],
      "metadata": {
        "id": "-0UX0_IYv2a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model and evaluate its performance on 10-fold CV and also on the test set. You might find sklearn [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) helpful to create the model (`tip`: use OneHotEncoder to encode the cateogrical features)\n",
        "\n",
        "Evaluate the performance using accuracy_score and classification_report from sklearn. Comment on the model's performance considering precision and recall. Comment on the generalisability of the model (does it have similar performance on the test set as with the cross validation set?)\n",
        "\n",
        "Use `X_train_imputed`, `y_train`, `X_test_imputed`, `y_test`."
      ],
      "metadata": {
        "id": "phg6jtlOwDy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluate feature importance\n",
        "Identify and visualise the top 10 most important features that influence when Gringotts approves a loan.\n",
        "\n",
        "Comment on the impact of the top few features."
      ],
      "metadata": {
        "id": "Oe32f8fMXvdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Understanding model's performance further"
      ],
      "metadata": {
        "id": "BNi65WcVyf6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn\n",
        "from fairlearn.metrics import MetricFrame, selection_rate"
      ],
      "metadata": {
        "id": "e0QfRBn0bFM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine if the model exhibits bias by performing significantly differently across various groups. For instance, assess whether the model's performance is superior or inferior for samples where the gender is male compared to other groups.\n",
        "\n",
        "Use the get_fairness_evaluation function to analyze the impact of this and other variables on model performance. This function uses Fairlearn to evaluate how the model fares across different classes, focusing on sensitive metrics such as accuracy, balanced accuracy, precision, and recall."
      ],
      "metadata": {
        "id": "kEeyVYkT0yMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fairness_evaluation(X_test, y_test, y_pred, columns):\n",
        "  sensitive_features_df = X_test[columns]\n",
        "\n",
        "  def precision_wrapper(y_true, y_pred): return precision_score(y_true, y_pred, pos_label='Yes', zero_division=0)\n",
        "  def recall_wrapper(y_true, y_pred): return recall_score(y_true, y_pred, pos_label='Yes', zero_division=0)\n",
        "\n",
        "  mf = MetricFrame(metrics={\n",
        "                      'accuracy': accuracy_score,\n",
        "                      'balanced_accuracy': balanced_accuracy_score,\n",
        "                      'precision': precision_wrapper,\n",
        "                      'recall': recall_wrapper,\n",
        "                      'count': lambda y_true, y_pred: y_true.shape[0]},\n",
        "                  y_true=y_test,\n",
        "                  y_pred=y_pred,\n",
        "                  sensitive_features=sensitive_features_df)\n",
        "\n",
        "  plot = mf.by_group.plot.bar(\n",
        "    subplots=True,\n",
        "    legend=True,\n",
        "    figsize=[12, 8],\n",
        "    title=\"Fairness Metrics Across Sensitive Features\"\n",
        "  )\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  return mf.by_group"
      ],
      "metadata": {
        "id": "oZLfxb242ZeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_fairness_evaluation(X_test_imputed, y_test, y_pred, ['gender'])"
      ],
      "metadata": {
        "id": "DdoQOqFbhDuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out different combinations. For example you can pass as input to the columns feature ['bloodline', gender']."
      ],
      "metadata": {
        "id": "wRPrNga_aA2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sociotechnical questions\n",
        "\n",
        "Reflection questions: As part of the assessment of this bounty you will also be graded on how you reflect on the following questions. When practicing AI Ethics, it is important to understand AI as socio-technical systems, and that although technical issues can be problematic, one need to understand the systematic and social structures giving rise to them in the first place.\n",
        "\n",
        "- Can all problems with bias be solved technically? If not, why?\n",
        "- What decision-making systems should be using algorithmic/AI approaches and which should not?\n",
        "- Is it just and fair to solve problems with bias by fixing technological constraints?"
      ],
      "metadata": {
        "id": "BzX8opL3HV8S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyu9NthUHdx1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}